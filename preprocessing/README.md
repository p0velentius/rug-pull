# ðŸ›  Data Preprocessing Pipeline

## ðŸ“Š Input/Output Overview

| **File** | **Input** | **Output** | **Rows** | **Processing Time** |
|----------|-----------|------------|----------|-------------------|
| `preprocessing.py` | `questions_clean.csv` | `questions_preprocessed.csv` | 6,977 | < 1 second |

## âš™ï¸ Processing Parameters

| **Parameter** | **Value** | **Description** |
|---------------|-----------|------------------|
| `do_lower` | `True` | Convert text to lowercase |
| `remove_emojis` | `True` | Remove all emoji characters |
| `remove_punct` | `True` | Remove punctuation marks |
| `remove_polite` | `True` | Remove polite phrases |
| `do_lemmatize` | `False` | **Disabled** lemmatization |
| `remove_short_tokens` | `True` | Remove short tokens |

## ðŸ“ Output Structure

The processed file `questions_preprocessed.csv` contains:

| Column | Description |
|--------|-------------|
| `q_id` | Question identifier |
| `query_clean` | Cleaned and processed text query |

## ðŸŽ¯ Key Processing Features

### ðŸ”¢ Anonymous Number Handling
- **Patterns**: `0000`, `XXXX`, `0`, `XX`, etc.
- **Replacement**: `âŸ¨ANON_NUMâŸ©`
- **Benefit**: Vectorizer recognizes single token instead of multiple variants

### ðŸ˜Š Emoji Removal
- **Method**: Regex based on Unicode ranges
- **Advantage**: More reliable than manual pattern matching

### ðŸ“ Punctuation Cleaning
- **Approach**: Careful removal while preserving special tokens
- **Preserved**: Words and special tokens like `âŸ¨ANON_NUMâŸ©`

## ðŸš€ Quick Start

```bash
python preprocessing.py
